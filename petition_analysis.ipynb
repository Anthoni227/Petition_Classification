{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Ensure input is a string\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "        text = text.strip()  # Remove leading/trailing spaces\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "        return text\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petition Department</th>\n",
       "      <th>Petition Description</th>\n",
       "      <th>Status</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Women &amp; Child Welfare</td>\n",
       "      <td>Address complaints of harassment in hostel acc...</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Education Department</td>\n",
       "      <td>No emergency medical facilities in schools for...</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Women &amp; Child Welfare</td>\n",
       "      <td>Victims of digital harassment find it difficul...</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Women &amp; Child Welfare</td>\n",
       "      <td>Lack of proper childcare facilities</td>\n",
       "      <td>Important</td>\n",
       "      <td>1553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Education Department</td>\n",
       "      <td>Lack of functional science laboratories severe...</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Petition Department                               Petition Description  \\\n",
       "0  Women & Child Welfare  Address complaints of harassment in hostel acc...   \n",
       "1   Education Department  No emergency medical facilities in schools for...   \n",
       "2  Women & Child Welfare  Victims of digital harassment find it difficul...   \n",
       "3  Women & Child Welfare                Lack of proper childcare facilities   \n",
       "4   Education Department  Lack of functional science laboratories severe...   \n",
       "\n",
       "      Status  Unnamed: 3  \n",
       "0     Urgent         109  \n",
       "1     Urgent         336  \n",
       "2     Urgent         444  \n",
       "3  Important        1553  \n",
       "4     Urgent         192  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"petition_train_data_org.csv\", encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Petition Department     4\n",
       "Petition Description    4\n",
       "Status                  4\n",
       "Unnamed: 3              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Petition Department     0\n",
       "Petition Description    0\n",
       "Status                  0\n",
       "Unnamed: 3              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status\n",
       "Urgent       1695\n",
       "Important     885\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "df[\"clean_text\"] = df[\"Petition Description\"].apply(preprocess_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder_dept = LabelEncoder()\n",
    "df[\"department_encoded\"] = label_encoder_dept.fit_transform(df[\"Petition Department\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_urgency = LabelEncoder()\n",
    "df[\"urgency_encoded\"] = label_encoder_urgency.fit_transform(df['Status'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X = df[\"clean_text\"]\n",
    "y_dept = df[\"department_encoded\"]\n",
    "y_urgency = df[\"urgency_encoded\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_dept, y_test_dept = train_test_split(X, y_dept, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train_urgency, y_test_urgency = train_test_split(X, y_urgency, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model selection\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42,max_depth=8,max_leaf_nodes=5),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42),\n",
    "    \"Naive Bayes\": MultinomialNB()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model_dept, best_acc_dept = None, 0\n",
    "best_model_urgency, best_acc_urgency = None, 0\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "best_model_dept, best_acc_dept = None, 0\n",
    "best_model_urgency, best_acc_urgency = None, 0\n",
    "\n",
    "# Train and evaluate ML models\n",
    "for name, model in models.items():\n",
    "    # Department Classification\n",
    "    model.fit(X_train_tfidf, y_train_dept)\n",
    "    y_pred_dept = model.predict(X_test_tfidf)\n",
    "    \n",
    "    acc_dept = accuracy_score(y_test_dept, y_pred_dept)\n",
    "    precision_dept, recall_dept, f1_dept, _ = precision_recall_fscore_support(y_test_dept, y_pred_dept, average='weighted')\n",
    "\n",
    "    results.append([\"Department\", name, acc_dept, precision_dept, recall_dept, f1_dept])\n",
    "    \n",
    "    if acc_dept > best_acc_dept:\n",
    "        best_acc_dept = acc_dept\n",
    "        best_model_dept = model\n",
    "\n",
    "    \n",
    "    model.fit(X_train_tfidf, y_train_urgency)\n",
    "    y_pred_urgency = model.predict(X_test_tfidf)\n",
    "    \n",
    "    acc_urgency = accuracy_score(y_test_urgency, y_pred_urgency)\n",
    "    precision_urgency, recall_urgency, f1_urgency, _ = precision_recall_fscore_support(y_test_urgency, y_pred_urgency, average='weighted')\n",
    "\n",
    "    results.append([\"Urgency\", name, acc_urgency, precision_urgency, recall_urgency, f1_urgency])\n",
    "    \n",
    "    if acc_urgency > best_acc_urgency:\n",
    "        best_acc_urgency = acc_urgency\n",
    "        best_model_urgency = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model - Deep Learning\n",
    "max_words = 5000\n",
    "max_len = 50\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_len)\n",
    "X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_len)\n",
    "\n",
    "y_train_dept_cat = to_categorical(y_train_dept)\n",
    "y_test_dept_cat = to_categorical(y_test_dept)\n",
    "y_train_urgency_cat = to_categorical(y_train_urgency)\n",
    "y_test_urgency_cat = to_categorical(y_test_urgency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antho\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.7650 - loss: 0.5102 - val_accuracy: 0.9438 - val_loss: 0.1554\n",
      "Epoch 2/5\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9604 - loss: 0.1114 - val_accuracy: 0.9690 - val_loss: 0.0878\n",
      "Epoch 3/5\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9775 - loss: 0.0578 - val_accuracy: 0.9729 - val_loss: 0.0674\n",
      "Epoch 4/5\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9859 - loss: 0.0403 - val_accuracy: 0.9787 - val_loss: 0.0633\n",
      "Epoch 5/5\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9767 - loss: 0.0573 - val_accuracy: 0.9845 - val_loss: 0.0502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e39c6b6f90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_dept = Sequential([\n",
    "    Embedding(max_words, 128, input_length=max_len),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(len(label_encoder_dept.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "lstm_dept.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_dept.fit(X_train_seq, y_train_dept_cat, epochs=5, batch_size=16, validation_data=(X_test_seq, y_test_dept_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate LSTM for Department\n",
    "lstm_acc_dept = lstm_dept.evaluate(X_test_seq, y_test_dept_cat, verbose=0)[1]\n",
    "y_pred_lstm_dept = np.argmax(lstm_dept.predict(X_test_seq), axis=1)\n",
    "precision_lstm_dept, recall_lstm_dept, f1_lstm_dept, _ = precision_recall_fscore_support(y_test_dept, y_pred_lstm_dept, average='weighted')\n",
    "\n",
    "results.append([\"Department\", \"LSTM\", lstm_acc_dept, precision_lstm_dept, recall_lstm_dept, f1_lstm_dept])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\antho\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.7062 - loss: 0.5621 - val_accuracy: 0.8992 - val_loss: 0.2575\n",
      "Epoch 2/5\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9434 - loss: 0.1708 - val_accuracy: 0.9516 - val_loss: 0.1455\n",
      "Epoch 3/5\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9745 - loss: 0.0712 - val_accuracy: 0.9632 - val_loss: 0.0856\n",
      "Epoch 4/5\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.9762 - loss: 0.0578 - val_accuracy: 0.9729 - val_loss: 0.0573\n",
      "Epoch 5/5\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.9843 - loss: 0.0383 - val_accuracy: 0.9826 - val_loss: 0.0366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e3a5f6b6e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model for Urgency Classification\n",
    "lstm_urgency = Sequential([\n",
    "    Embedding(max_words, 128, input_length=max_len),\n",
    "    SpatialDropout1D(0.2),\n",
    "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(len(label_encoder_urgency.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "lstm_urgency.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_urgency.fit(X_train_seq, y_train_urgency_cat, epochs=5, batch_size=16, validation_data=(X_test_seq, y_test_urgency_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate LSTM for Urgency\n",
    "lstm_acc_urgency = lstm_urgency.evaluate(X_test_seq, y_test_urgency_cat, verbose=0)[1]\n",
    "y_pred_lstm_urgency = np.argmax(lstm_urgency.predict(X_test_seq), axis=1)\n",
    "precision_lstm_urgency, recall_lstm_urgency, f1_lstm_urgency, _ = precision_recall_fscore_support(y_test_urgency, y_pred_lstm_urgency, average='weighted')\n",
    "\n",
    "results.append([\"Urgency\", \"LSTM\", lstm_acc_urgency, precision_lstm_urgency, recall_lstm_urgency, f1_lstm_urgency])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Task              Model  Accuracy  Precision    Recall  F1-Score\n",
      "0  Department      Random Forest  0.722868   0.802606  0.722868  0.636678\n",
      "1     Urgency      Random Forest  0.678295   0.782598  0.678295  0.555958\n",
      "2  Department  Gradient Boosting  0.974806   0.974919  0.974806  0.974651\n",
      "3     Urgency  Gradient Boosting  0.885659   0.885836  0.885659  0.882874\n",
      "4  Department                SVM  0.978682   0.978655  0.978682  0.978664\n",
      "5     Urgency                SVM  0.963178   0.963324  0.963178  0.962914\n",
      "6  Department        Naive Bayes  0.941860   0.941799  0.941860  0.941227\n",
      "7     Urgency        Naive Bayes  0.918605   0.920411  0.918605  0.916709\n",
      "8  Department               LSTM  0.984496   0.984528  0.984496  0.984443\n",
      "9     Urgency               LSTM  0.982558   0.982540  0.982558  0.982545\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with results\n",
    "df_results = pd.DataFrame(results, columns=[\"Task\", \"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"])\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM models and required files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Select LSTM as the best model for both tasks\n",
    "best_model_dept = lstm_dept\n",
    "best_model_urgency = lstm_urgency\n",
    "\n",
    "# Save models and tokenizer for Flask Deployment\n",
    "with open(\"department_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model_dept, f)\n",
    "\n",
    "with open(\"urgency_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model_urgency, f)\n",
    "\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "with open(\"label_encoder_dept.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoder_dept, f)\n",
    "\n",
    "with open(\"label_encoder_urgency.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoder_urgency, f)\n",
    "\n",
    "# Save evaluation results to CSV\n",
    "df_results.to_csv(\"model_evaluation_results.csv\", index=False)\n",
    "\n",
    "print(\"LSTM models and required files saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_petition(text):\n",
    "    text = preprocess_text(text) \n",
    "\n",
    "    # Tokenize and pad input text\n",
    "    text_seq = tokenizer.texts_to_sequences([text])\n",
    "    text_padded = pad_sequences(text_seq, maxlen=50)  \n",
    "\n",
    "    # Predict department using LSTM\n",
    "    dept_pred = np.argmax(best_model_dept.predict(text_padded), axis=1)[0]\n",
    "    department = label_encoder_dept.inverse_transform([dept_pred])[0]\n",
    "\n",
    "    # Predict urgency using LSTM\n",
    "    urgency_pred = np.argmax(best_model_urgency.predict(text_padded), axis=1)[0]\n",
    "    urgency = label_encoder_urgency.inverse_transform([urgency_pred])[0]\n",
    "\n",
    "    return department, urgency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Predicted Department: Education Department, Urgency: Urgent\n"
     ]
    }
   ],
   "source": [
    "new_petition = \"food poision\"\n",
    "dept, urgency = classify_petition(new_petition)\n",
    "print(f\"Predicted Department: {dept}, Urgency: {urgency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
